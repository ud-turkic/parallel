{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POEIqZuR4FFC",
        "outputId": "cbede81f-6d1e-4872-b705-feb056eca19a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting conllu\n",
            "  Downloading conllu-6.0.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading conllu-6.0.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: conllu\n",
            "Successfully installed conllu-6.0.0\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install conllu\n",
        "!pip install matplotlib seaborn pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import conllu\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "import itertools"
      ],
      "metadata": {
        "id": "rfnZvfp64zgS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_pos_edit_distance(sentence1, sentence2):\n",
        "    \"\"\"\n",
        "    Calculate the edit distance between two sentences based on POS tags.\n",
        "\n",
        "    Args:\n",
        "        sentence1: A list of tokens from first treebank sentence\n",
        "        sentence2: A list of tokens from second treebank sentence\n",
        "\n",
        "    Returns:\n",
        "        Edit distance value and normalized edit distance (0-1 scale)\n",
        "    \"\"\"\n",
        "    # Extract POS tags from each sentence\n",
        "    pos_seq1 = [token[\"upos\"] for token in sentence1 if token[\"upos\"]]\n",
        "    pos_seq2 = [token[\"upos\"] for token in sentence2 if token[\"upos\"]]\n",
        "\n",
        "    # Implement Levenshtein distance\n",
        "    m, n = len(pos_seq1), len(pos_seq2)\n",
        "\n",
        "    # Create matrix\n",
        "    dp = [[0 for _ in range(n + 1)] for _ in range(m + 1)]\n",
        "\n",
        "    # Initialize first row and column\n",
        "    for i in range(m + 1):\n",
        "        dp[i][0] = i\n",
        "    for j in range(n + 1):\n",
        "        dp[0][j] = j\n",
        "\n",
        "    # Fill the matrix\n",
        "    for i in range(1, m + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            cost = 0 if pos_seq1[i-1] == pos_seq2[j-1] else 1\n",
        "            dp[i][j] = min(\n",
        "                dp[i-1][j] + 1,      # deletion\n",
        "                dp[i][j-1] + 1,      # insertion\n",
        "                dp[i-1][j-1] + cost  # substitution\n",
        "            )\n",
        "\n",
        "    edit_distance = dp[m][n]\n",
        "\n",
        "    # Normalize by the length of the longer sequence\n",
        "    max_length = max(m, n)\n",
        "    normalized_distance = edit_distance / max_length if max_length > 0 else 0\n",
        "\n",
        "    return edit_distance, normalized_distance\n",
        "\n",
        "class MultilingualTreebankAnalyzer:\n",
        "    \"\"\"Analyzer for multilingual parallel treebanks to compare POS ordering across languages.\"\"\"\n",
        "\n",
        "    def __init__(self, treebank_files):\n",
        "        \"\"\"\n",
        "        Initialize with paths to multiple parallel CoNLL-U files.\n",
        "\n",
        "        Args:\n",
        "            treebank_files: Dictionary mapping language names to file paths\n",
        "        \"\"\"\n",
        "        self.languages = list(treebank_files.keys())\n",
        "        self.treebank_files = treebank_files\n",
        "\n",
        "        # Load all treebanks\n",
        "        self.treebanks = {}\n",
        "        self.sentence_counts = {}\n",
        "\n",
        "        for lang, file_path in treebank_files.items():\n",
        "            try:\n",
        "                self.treebanks[lang] = self._load_data(file_path)\n",
        "                self.sentence_counts[lang] = len(self.treebanks[lang])\n",
        "                print(f\"Loaded {lang} treebank: {self.sentence_counts[lang]} sentences\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {lang} treebank: {e}\")\n",
        "                self.treebanks[lang] = []\n",
        "                self.sentence_counts[lang] = 0\n",
        "\n",
        "        # Get the minimum number of sentences across all treebanks\n",
        "        self.min_sentences = min(self.sentence_counts.values()) if self.sentence_counts else 0\n",
        "\n",
        "        # Store results\n",
        "        self.edit_distance_results = {}\n",
        "\n",
        "    def _load_data(self, file_path):\n",
        "        \"\"\"Load the CoNLL-U file into a list of sentences.\"\"\"\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            return list(conllu.parse(f.read()))\n",
        "\n",
        "    def calculate_all_edit_distances(self):\n",
        "        \"\"\"\n",
        "        Calculate edit distances between all language pairs.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with language pair tuples as keys and distance stats as values\n",
        "        \"\"\"\n",
        "        # Generate all possible language pairs\n",
        "        language_pairs = list(itertools.combinations(self.languages, 2))\n",
        "\n",
        "        for lang1, lang2 in language_pairs:\n",
        "            # Get treebanks\n",
        "            treebank1 = self.treebanks[lang1]\n",
        "            treebank2 = self.treebanks[lang2]\n",
        "\n",
        "            # Calculate min sentences between these two languages\n",
        "            min_sent = min(len(treebank1), len(treebank2))\n",
        "\n",
        "            # Calculate edit distances\n",
        "            edit_distances = []\n",
        "            normalized_distances = []\n",
        "\n",
        "            for i in range(min_sent):\n",
        "                sent1 = treebank1[i]\n",
        "                sent2 = treebank2[i]\n",
        "\n",
        "                ed, norm_ed = calculate_pos_edit_distance(sent1, sent2)\n",
        "                edit_distances.append(ed)\n",
        "                normalized_distances.append(norm_ed)\n",
        "\n",
        "            # Calculate statistics\n",
        "            if edit_distances:\n",
        "                avg_ed = sum(edit_distances) / len(edit_distances)\n",
        "                avg_norm_ed = sum(normalized_distances) / len(normalized_distances)\n",
        "                max_ed = max(edit_distances)\n",
        "                min_ed = min(edit_distances)\n",
        "\n",
        "                # Find examples of min and max edit distance\n",
        "                min_idx = edit_distances.index(min_ed)\n",
        "                max_idx = edit_distances.index(max_ed)\n",
        "\n",
        "                # Calculate percentiles\n",
        "                sorted_norm = sorted(normalized_distances)\n",
        "                median_norm = sorted_norm[len(sorted_norm) // 2]\n",
        "                q1_norm = sorted_norm[len(sorted_norm) // 4]\n",
        "                q3_norm = sorted_norm[3 * len(sorted_norm) // 4]\n",
        "\n",
        "                stats = {\n",
        "                    \"avg_edit_distance\": avg_ed,\n",
        "                    \"avg_normalized_distance\": avg_norm_ed,\n",
        "                    \"max_edit_distance\": max_ed,\n",
        "                    \"min_edit_distance\": min_ed,\n",
        "                    \"median_normalized\": median_norm,\n",
        "                    \"q1_normalized\": q1_norm,\n",
        "                    \"q3_normalized\": q3_norm,\n",
        "                    \"min_example_idx\": min_idx,\n",
        "                    \"max_example_idx\": max_idx,\n",
        "                    \"all_distances\": edit_distances,\n",
        "                    \"all_normalized\": normalized_distances\n",
        "                }\n",
        "\n",
        "                # Store results\n",
        "                self.edit_distance_results[(lang1, lang2)] = stats\n",
        "\n",
        "        return self.edit_distance_results\n",
        "\n",
        "    def generate_edit_distance_matrix(self):\n",
        "        \"\"\"\n",
        "        Generate a matrix of average edit distances between all language pairs.\n",
        "\n",
        "        Returns:\n",
        "            Pandas DataFrame containing the distance matrix\n",
        "        \"\"\"\n",
        "        # Make sure we have calculated distances\n",
        "        if not self.edit_distance_results:\n",
        "            self.calculate_all_edit_distances()\n",
        "\n",
        "        # Create an empty DataFrame\n",
        "        dist_matrix = pd.DataFrame(index=self.languages, columns=self.languages)\n",
        "\n",
        "        # Fill diagonal with zeros (distance to self is zero)\n",
        "        for lang in self.languages:\n",
        "            dist_matrix.loc[lang, lang] = 0.0\n",
        "\n",
        "        # Fill in the distances from our calculations\n",
        "        for (lang1, lang2), stats in self.edit_distance_results.items():\n",
        "            dist_matrix.loc[lang1, lang2] = stats[\"avg_normalized_distance\"]\n",
        "            dist_matrix.loc[lang2, lang1] = stats[\"avg_normalized_distance\"]  # Matrix is symmetric\n",
        "\n",
        "        return dist_matrix\n",
        "\n",
        "    def visualize_edit_distance_matrix(self):\n",
        "        \"\"\"Create and save a heatmap of the edit distance matrix.\"\"\"\n",
        "        dist_matrix = self.generate_edit_distance_matrix()\n",
        "\n",
        "        dist_matrix = dist_matrix.astype(float)\n",
        "\n",
        "        dist_matrix = dist_matrix.fillna(0.0)\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(dist_matrix, annot=True, cmap=\"YlGnBu\", fmt=\".3f\")\n",
        "        plt.title(\"Normalized Edit Distance Between Languages (POS Sequences)\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"multilingual_edit_distances.png\")\n",
        "        plt.close()\n",
        "        print(\"\\nGenerated 'multilingual_edit_distances.png'\")\n",
        "\n",
        "        return dist_matrix\n",
        "\n",
        "    def print_edit_distance_stats(self):\n",
        "        \"\"\"Print detailed statistics about edit distances between all language pairs.\"\"\"\n",
        "        # Make sure we have calculated distances\n",
        "        if not self.edit_distance_results:\n",
        "            self.calculate_all_edit_distances()\n",
        "\n",
        "        print(\"\\nDetailed Edit Distance Statistics\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        for (lang1, lang2), stats in self.edit_distance_results.items():\n",
        "            print(f\"\\n{lang1} vs {lang2}:\")\n",
        "            print(\"-\" * 40)\n",
        "            print(f\"Number of sentence pairs analyzed: {len(stats['all_distances'])}\")\n",
        "            print(f\"Average edit distance: {stats['avg_edit_distance']:.2f}\")\n",
        "            print(f\"Average normalized edit distance: {stats['avg_normalized_distance']:.2f} (0-1 scale)\")\n",
        "            print(f\"Minimum edit distance: {stats['min_edit_distance']}\")\n",
        "            print(f\"Maximum edit distance: {stats['max_edit_distance']}\")\n",
        "            print(f\"Normalized distance quartiles (Q1/Median/Q3): \"\n",
        "                  f\"{stats['q1_normalized']:.2f} / {stats['median_normalized']:.2f} / {stats['q3_normalized']:.2f}\")\n",
        "\n",
        "            # Print examples of min and max edit distance\n",
        "            print(\"\\n  Example with minimum edit distance:\")\n",
        "            self._print_parallel_example(lang1, lang2, stats['min_example_idx'])\n",
        "\n",
        "            print(\"\\n  Example with maximum edit distance:\")\n",
        "            self._print_parallel_example(lang1, lang2, stats['max_example_idx'])\n",
        "\n",
        "            # Create histogram for this language pair\n",
        "            plt.figure(figsize=(8, 5))\n",
        "            plt.hist(stats['all_normalized'], bins=20, alpha=0.7, color='green')\n",
        "            plt.title(f'Distribution of Normalized Edit Distances: {lang1} vs {lang2}')\n",
        "            plt.xlabel('Normalized Edit Distance (0-1)')\n",
        "            plt.ylabel('Frequency')\n",
        "            plt.grid(alpha=0.3)\n",
        "            plt.savefig(f'edit_distance_{lang1}_{lang2}.png')\n",
        "            plt.close()\n",
        "            print(f\"  Generated 'edit_distance_{lang1}_{lang2}.png'\")\n",
        "\n",
        "    def _print_parallel_example(self, lang1, lang2, idx):\n",
        "        \"\"\"Print a pair of parallel sentences with their POS sequences.\"\"\"\n",
        "        try:\n",
        "            sent1 = self.treebanks[lang1][idx]\n",
        "            sent2 = self.treebanks[lang2][idx]\n",
        "\n",
        "            # Extract text and POS tags\n",
        "            text1 = ' '.join([token[\"form\"] for token in sent1])\n",
        "            text2 = ' '.join([token[\"form\"] for token in sent2])\n",
        "\n",
        "            pos1 = [token[\"upos\"] for token in sent1 if token[\"upos\"]]\n",
        "            pos2 = [token[\"upos\"] for token in sent2 if token[\"upos\"]]\n",
        "\n",
        "            print(f\"  {lang1}: {text1}\")\n",
        "            print(f\"  {lang1} POS: {' '.join(pos1)}\")\n",
        "            print(f\"  {lang2}: {text2}\")\n",
        "            print(f\"  {lang2} POS: {' '.join(pos2)}\")\n",
        "\n",
        "            # Calculate and print edit distance for this example\n",
        "            ed, norm_ed = calculate_pos_edit_distance(sent1, sent2)\n",
        "            print(f\"  Edit distance: {ed}, Normalized: {norm_ed:.2f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error printing example {idx}: {e}\")\n",
        "\n",
        "\n",
        "    def generate_dendrogram(self):\n",
        "        \"\"\"\n",
        "        Generate a dendrogram showing language clustering based on edit distances.\n",
        "        This visualizes which languages have the most similar POS ordering patterns.\n",
        "        \"\"\"\n",
        "        # Get distance matrix\n",
        "        dist_matrix = self.generate_edit_distance_matrix()\n",
        "\n",
        "        # Create linkage matrix for hierarchical clustering\n",
        "        from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "\n",
        "        # Convert DataFrame to condensed distance matrix (flattened upper triangular)\n",
        "        distances = []\n",
        "        for i in range(len(self.languages)):\n",
        "            for j in range(i+1, len(self.languages)):\n",
        "                distances.append(dist_matrix.iloc[i, j])\n",
        "\n",
        "        # Calculate linkage\n",
        "        Z = linkage(distances, method='average')\n",
        "\n",
        "        # Plot dendrogram\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        dendrogram(Z, labels=self.languages, leaf_rotation=90)\n",
        "        plt.title('Language Clustering by POS Order Similarity')\n",
        "        plt.xlabel('Languages')\n",
        "        plt.ylabel('Distance')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('language_dendrogram.png')\n",
        "        plt.close()\n",
        "        print(\"\\nGenerated 'language_dendrogram.png'\")\n",
        "\n",
        "    def analyze_all(self):\n",
        "        \"\"\"Run all analyses and generate all visualizations.\"\"\"\n",
        "        self.calculate_all_edit_distances()\n",
        "        self.visualize_edit_distance_matrix()\n",
        "        self.print_edit_distance_stats()\n",
        "        self.generate_dendrogram()\n",
        "\n",
        "def analyze_multilingual_treebanks(treebank_files):\n",
        "    \"\"\"\n",
        "    Analyze multiple parallel treebanks.\n",
        "\n",
        "    Args:\n",
        "        treebank_files: Dictionary mapping language names to file paths\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"MULTILINGUAL TREEBANK ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    try:\n",
        "        analyzer = MultilingualTreebankAnalyzer(treebank_files)\n",
        "        analyzer.analyze_all()\n",
        "    except Exception as e:\n",
        "        print(f\"Error in multilingual analysis: {e}\")\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Get the treebank paths\n",
        "    num_langs = int(input(\"How many languages do you want to compare? \"))\n",
        "\n",
        "    treebank_files = {}\n",
        "    for i in range(num_langs):\n",
        "        lang = input(f\"Enter language name #{i+1}: \")\n",
        "        path = input(f\"Enter path to {lang} treebank file: \")\n",
        "        treebank_files[lang] = path\n",
        "\n",
        "    # Run multilingual analysis\n",
        "    if len(treebank_files) > 1:\n",
        "        analyze_multilingual_treebanks(treebank_files)\n",
        "    else:\n",
        "        print(\"At least 2 languages are needed for comparison.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfFrGvxS4_45",
        "outputId": "c7d17895-5a9e-4146-aee3-f988d0bdb6fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How many languages do you want to compare? 4\n",
            "Enter language name #1: Azeri\n",
            "Enter path to Azeri treebank file: /content/az_tuecl-ud-test.conllu\n",
            "Enter language name #2: Turkish\n",
            "Enter path to Turkish treebank file: /content/tr_tuecl-ud-test.fa.conllu\n",
            "Enter language name #3: Kyrgyz\n",
            "Enter path to Kyrgyz treebank file: /content/ky_tuecl-ud-test.conllu\n",
            "Enter language name #4: Uzbek\n",
            "Enter path to Uzbek treebank file: /content/uz_tuecl-ud-test.conllu\n",
            "\n",
            "============================================================\n",
            "MULTILINGUAL TREEBANK ANALYSIS\n",
            "============================================================\n",
            "Loaded Azeri treebank: 109 sentences\n",
            "Loaded Turkish treebank: 148 sentences\n",
            "Loaded Kyrgyz treebank: 145 sentences\n",
            "Loaded Uzbek treebank: 148 sentences\n",
            "\n",
            "Generated 'multilingual_edit_distances.png'\n",
            "\n",
            "Detailed Edit Distance Statistics\n",
            "============================================================\n",
            "\n",
            "Azeri vs Turkish:\n",
            "----------------------------------------\n",
            "Number of sentence pairs analyzed: 109\n",
            "Average edit distance: 4.74\n",
            "Average normalized edit distance: 0.59 (0-1 scale)\n",
            "Minimum edit distance: 0\n",
            "Maximum edit distance: 15\n",
            "Normalized distance quartiles (Q1/Median/Q3): 0.50 / 0.60 / 0.71\n",
            "\n",
            "  Example with minimum edit distance:\n",
            "  Azeri: Qız yoldaşına namә yazdı .\n",
            "  Azeri POS: NOUN NOUN NOUN VERB PUNCT\n",
            "  Turkish: Kız arkadaşına mektup yazdı .\n",
            "  Turkish POS: NOUN NOUN NOUN VERB PUNCT\n",
            "  Edit distance: 0, Normalized: 0.00\n",
            "\n",
            "  Example with maximum edit distance:\n",
            "  Azeri: Gecəni qalan qonax qapını çalmışdı , amma ev sahab sil - süpür elirdi və resturandan sifariş verən qəza hələ gələcəgidi .\n",
            "  Azeri POS: NOUN VERB NOUN NOUN VERB PUNCT CCONJ NOUN NOUN VERB PUNCT VERB VERB CCONJ NOUN NOUN VERB NOUN ADV VERB PUNCT\n",
            "  Turkish: Peter ve Mary birbirlerini kucakladılar ve ondan sonra odadan çıktılar .\n",
            "  Turkish POS: PROPN CCONJ PROPN PRON VERB CCONJ PRON ADV NOUN VERB PUNCT\n",
            "  Edit distance: 15, Normalized: 0.71\n",
            "  Generated 'edit_distance_Azeri_Turkish.png'\n",
            "\n",
            "Azeri vs Kyrgyz:\n",
            "----------------------------------------\n",
            "Number of sentence pairs analyzed: 109\n",
            "Average edit distance: 5.43\n",
            "Average normalized edit distance: 0.61 (0-1 scale)\n",
            "Minimum edit distance: 0\n",
            "Maximum edit distance: 17\n",
            "Normalized distance quartiles (Q1/Median/Q3): 0.50 / 0.67 / 0.73\n",
            "\n",
            "  Example with minimum edit distance:\n",
            "  Azeri: Qız yoldaşına namә yazdı .\n",
            "  Azeri POS: NOUN NOUN NOUN VERB PUNCT\n",
            "  Kyrgyz: Кыз досуна кат жазды .\n",
            "  Kyrgyz POS: NOUN NOUN NOUN VERB PUNCT\n",
            "  Edit distance: 0, Normalized: 0.00\n",
            "\n",
            "  Example with maximum edit distance:\n",
            "  Azeri: Cələsə elam olanda o qədər təəccüb eləmişdi ki mənə elə mat - mat baxırdı .\n",
            "  Azeri POS: NOUN NOUN AUX PRON ADP NOUN VERB SCONJ NOUN ADV ADV PUNCT ADV VERB PUNCT\n",
            "  Kyrgyz: Түнѳп калчу конок эшикти такылдатыптыр , бирок үйдүн ээси дагы эле үйдү жыйнап жаткан , ал эми ал ресторандан буюртма берген тамак келмек болчу .\n",
            "  Kyrgyz POS: VERB VERB NOUN NOUN VERB PUNCT CCONJ NOUN NOUN ADV ADV NOUN VERB AUX PUNCT CCONJ ADV PRON NOUN NOUN VERB NOUN VERB AUX PUNCT\n",
            "  Edit distance: 17, Normalized: 0.68\n",
            "  Generated 'edit_distance_Azeri_Kyrgyz.png'\n",
            "\n",
            "Azeri vs Uzbek:\n",
            "----------------------------------------\n",
            "Number of sentence pairs analyzed: 109\n",
            "Average edit distance: 4.96\n",
            "Average normalized edit distance: 0.59 (0-1 scale)\n",
            "Minimum edit distance: 0\n",
            "Maximum edit distance: 17\n",
            "Normalized distance quartiles (Q1/Median/Q3): 0.50 / 0.62 / 0.71\n",
            "\n",
            "  Example with minimum edit distance:\n",
            "  Azeri: Qız yoldaşına namә yazdı .\n",
            "  Azeri POS: NOUN NOUN NOUN VERB PUNCT\n",
            "  Uzbek: Qiz do‘stiga xat yozdi .\n",
            "  Uzbek POS: NOUN NOUN NOUN VERB PUNCT\n",
            "  Edit distance: 0, Normalized: 0.00\n",
            "\n",
            "  Example with maximum edit distance:\n",
            "  Azeri: Cələsə elam olanda o qədər təəccüb eləmişdi ki mənə elə mat - mat baxırdı .\n",
            "  Azeri POS: NOUN NOUN AUX PRON ADP NOUN VERB SCONJ NOUN ADV ADV PUNCT ADV VERB PUNCT\n",
            "  Uzbek: Yotgani kelgan mehmon eshikni taqillatdi , lekin uy egasi hali ham tozalash ishlari bilan band edi , restorandan buyurtma qilgan taomi esa hali kelmagan edi .\n",
            "  Uzbek POS: VERB VERB NOUN NOUN VERB PUNCT CCONJ NOUN NOUN ADV ADV VERB NOUN ADV ADJ AUX PUNCT NOUN NOUN VERB NOUN CCONJ ADV VERB AUX PUNCT\n",
            "  Edit distance: 17, Normalized: 0.65\n",
            "  Generated 'edit_distance_Azeri_Uzbek.png'\n",
            "\n",
            "Turkish vs Kyrgyz:\n",
            "----------------------------------------\n",
            "Number of sentence pairs analyzed: 145\n",
            "Average edit distance: 4.50\n",
            "Average normalized edit distance: 0.56 (0-1 scale)\n",
            "Minimum edit distance: 0\n",
            "Maximum edit distance: 14\n",
            "Normalized distance quartiles (Q1/Median/Q3): 0.42 / 0.57 / 0.71\n",
            "\n",
            "  Example with minimum edit distance:\n",
            "  Turkish: Kız arkadaşına mektup yazdı .\n",
            "  Turkish POS: NOUN NOUN NOUN VERB PUNCT\n",
            "  Kyrgyz: Кыз досуна кат жазды .\n",
            "  Kyrgyz POS: NOUN NOUN NOUN VERB PUNCT\n",
            "  Edit distance: 0, Normalized: 0.00\n",
            "\n",
            "  Example with maximum edit distance:\n",
            "  Turkish: Bugün mü yapılacak etkinlik ?\n",
            "  Turkish POS: ADV AUX VERB NOUN PUNCT\n",
            "  Kyrgyz: Чогулуш боло тургандыгы айтылып жаткан учурда , ал ушунчалык таң калгандыктан окшойт , мени караган бойдон калды .\n",
            "  Kyrgyz POS: NOUN VERB PART VERB AUX NOUN PUNCT PROPN ADV NOUN VERB VERB PUNCT PRON VERB NOUN VERB PUNCT\n",
            "  Edit distance: 14, Normalized: 0.78\n",
            "  Generated 'edit_distance_Turkish_Kyrgyz.png'\n",
            "\n",
            "Turkish vs Uzbek:\n",
            "----------------------------------------\n",
            "Number of sentence pairs analyzed: 148\n",
            "Average edit distance: 1.72\n",
            "Average normalized edit distance: 0.22 (0-1 scale)\n",
            "Minimum edit distance: 0\n",
            "Maximum edit distance: 9\n",
            "Normalized distance quartiles (Q1/Median/Q3): 0.00 / 0.20 / 0.33\n",
            "\n",
            "  Example with minimum edit distance:\n",
            "  Turkish: Kız arkadaşına mektup yazdı .\n",
            "  Turkish POS: NOUN NOUN NOUN VERB PUNCT\n",
            "  Uzbek: Qiz do‘stiga xat yozdi .\n",
            "  Uzbek POS: NOUN NOUN NOUN VERB PUNCT\n",
            "  Edit distance: 0, Normalized: 0.00\n",
            "\n",
            "  Example with maximum edit distance:\n",
            "  Turkish: Yatılı kalacak misafir kapıyı çalmıştı ama ev sahibi hala temizlik yapıyordu , restorandan sipariş ettiği yemek ise daha gelecekti .\n",
            "  Turkish POS: ADJ VERB NOUN NOUN VERB CCONJ NOUN NOUN ADV NOUN VERB PUNCT NOUN NOUN VERB NOUN ADV ADV VERB PUNCT\n",
            "  Uzbek: Yotgani kelgan mehmon eshikni taqillatdi , lekin uy egasi hali ham tozalash ishlari bilan band edi , restorandan buyurtma qilgan taomi esa hali kelmagan edi .\n",
            "  Uzbek POS: VERB VERB NOUN NOUN VERB PUNCT CCONJ NOUN NOUN ADV ADV VERB NOUN ADV ADJ AUX PUNCT NOUN NOUN VERB NOUN CCONJ ADV VERB AUX PUNCT\n",
            "  Edit distance: 9, Normalized: 0.35\n",
            "  Generated 'edit_distance_Turkish_Uzbek.png'\n",
            "\n",
            "Kyrgyz vs Uzbek:\n",
            "----------------------------------------\n",
            "Number of sentence pairs analyzed: 145\n",
            "Average edit distance: 4.55\n",
            "Average normalized edit distance: 0.56 (0-1 scale)\n",
            "Minimum edit distance: 0\n",
            "Maximum edit distance: 14\n",
            "Normalized distance quartiles (Q1/Median/Q3): 0.40 / 0.60 / 0.71\n",
            "\n",
            "  Example with minimum edit distance:\n",
            "  Kyrgyz: Кыз досуна кат жазды .\n",
            "  Kyrgyz POS: NOUN NOUN NOUN VERB PUNCT\n",
            "  Uzbek: Qiz do‘stiga xat yozdi .\n",
            "  Uzbek POS: NOUN NOUN NOUN VERB PUNCT\n",
            "  Edit distance: 0, Normalized: 0.00\n",
            "\n",
            "  Example with maximum edit distance:\n",
            "  Kyrgyz: Чогулуш боло тургандыгы айтылып жаткан учурда , ал ушунчалык таң калгандыктан окшойт , мени караган бойдон калды .\n",
            "  Kyrgyz POS: NOUN VERB PART VERB AUX NOUN PUNCT PROPN ADV NOUN VERB VERB PUNCT PRON VERB NOUN VERB PUNCT\n",
            "  Uzbek: Tadbir bugun bo‘ladimi ?\n",
            "  Uzbek POS: NOUN ADV VERB PUNCT\n",
            "  Edit distance: 14, Normalized: 0.78\n",
            "  Generated 'edit_distance_Kyrgyz_Uzbek.png'\n",
            "\n",
            "Generated 'language_dendrogram.png'\n"
          ]
        }
      ]
    }
  ]
}